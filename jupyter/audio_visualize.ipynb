{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQI4U7A1h34o",
    "outputId": "ed7d147f-4eaf-4cda-ca82-0fe6c48c1f01"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FPS = 24\n",
    "FFT_WINDOW_SECONDS = 0.25 # how many seconds of audio make up an FFT window\n",
    "\n",
    "# Note range to display\n",
    "FREQ_MIN = 10\n",
    "FREQ_MAX = 1000\n",
    "\n",
    "# Notes to display\n",
    "TOP_NOTES = 3\n",
    "\n",
    "# Names of the notes\n",
    "NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "# Output size. Generally use SCALE for higher res, unless you need a non-standard aspect ratio.\n",
    "RESOLUTION = (1920, 1080)\n",
    "SCALE = 1 # 0.5=QHD(960x540), 1=HD(1920x1080), 2=4K(3840x2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eOd8Tm-jIW5",
    "outputId": "35c9b414-3e56-46fd-db62-79712144f834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29937577, 29358674, 29358674, ...,        0,        0,        0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile # get the api\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "AUDIO_FILE = \"./content/sample_audio.wav\"\n",
    "\n",
    "fs, data = wavfile.read(AUDIO_FILE) # load the data\n",
    "audio = data.T[0] # this is a two channel soundtrack, get the first track\n",
    "\n",
    "audio_quant = np.array(audio)\n",
    "audio_hw = np.int32(audio_quant/np.max(abs(audio_quant)) * (2**31 - 1))\n",
    "\n",
    "FRAME_STEP = (fs / FPS) # audio samples per video frame\n",
    "FFT_WINDOW_SIZE = int(fs * FFT_WINDOW_SECONDS)\n",
    "AUDIO_LENGTH = len(audio_hw)/fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqxOflIuM_eT"
   },
   "source": [
    "Several utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yg2kx9olG3ib"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_fft(p, xf, fs, notes, dimensions=(960,540)):\n",
    "  layout = go.Layout(\n",
    "      title=\"frequency spectrum\",\n",
    "      autosize=False,\n",
    "      width=dimensions[0],\n",
    "      height=dimensions[1],\n",
    "      xaxis_title=\"Frequency (note)\",\n",
    "      yaxis_title=\"Magnitude\",\n",
    "      font={'size' : 18}\n",
    "  )\n",
    "\n",
    "  fig = go.Figure(layout=layout,\n",
    "                  layout_xaxis_range=[FREQ_MIN,FREQ_MAX],\n",
    "                  layout_yaxis_range=[0,1]\n",
    "                  )\n",
    "  \n",
    "  fig.add_trace(go.Scatter(\n",
    "      x = xf,\n",
    "      y = p))\n",
    "  \n",
    "  for note in notes:\n",
    "    fig.add_annotation(x=note[0]+10, y=note[2],\n",
    "            text=note[1],\n",
    "            font = {'size' : 24},\n",
    "            showarrow=False)\n",
    "  return fig\n",
    "\n",
    "def find_top_notes(fft,num):\n",
    "  if np.max(fft.real)<0.001:\n",
    "    return []\n",
    "\n",
    "  lst = [x for x in enumerate(fft.real)]\n",
    "  lst = sorted(lst, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "  idx = 0\n",
    "  found = []\n",
    "  found_note = set()\n",
    "  while( (idx<len(lst)) and (len(found)<num) ):\n",
    "    f = xf[lst[idx][0]]\n",
    "    y = lst[idx][1]\n",
    "    n = freq_to_number(f)\n",
    "    n0 = int(round(n))\n",
    "    name = note_name(n0)\n",
    "\n",
    "    if name not in found_note:\n",
    "      found_note.add(name)\n",
    "      s = [f,note_name(n0),y]\n",
    "      found.append(s)\n",
    "    idx += 1\n",
    "    \n",
    "  return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t98k4AMRHy-o"
   },
   "source": [
    "Run the FFT on individual samples of the audio and generate video frames of the frequency chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "overlay = Overlay(\"./overlay/fft.bit\")\n",
    "fft_overlay = overlay.fft_warp_0\n",
    "# ? overlay\n",
    "FRAME_COUNT = int(AUDIO_LENGTH*FPS)\n",
    "FRAME_OFFSET = int(len(audio_hw)/FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import allocate\n",
    "\n",
    "# Allocating memory for IP usage\n",
    "input_buffer = allocate(shape=(FRAME_OFFSET*FRAME_COUNT,), dtype='i4')\n",
    "output_buffer = allocate(shape=(2**14 *FRAME_COUNT,), dtype='i4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './content/*.png': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.offline as py\n",
    "\n",
    "!rm ./content/*.png\n",
    "\n",
    "# Functions to find the notes\n",
    "def freq_to_number(f): return 69 + 12*np.log2(f/440.0)\n",
    "def number_to_freq(n): return 440 * 2.0**((n-69)/12.0)\n",
    "def note_name(n): return NOTE_NAMES[n % 12] + str(int(n/12 - 1))\n",
    "\n",
    "# Process audio data\n",
    "audio_hw = audio_hw[0:FRAME_COUNT*FRAME_OFFSET]\n",
    "np.copyto(input_buffer, np.int32(audio_hw))\n",
    "\n",
    "input_buffer[10000:10009]\n",
    "\n",
    "# Write data length to the corresponding register\n",
    "fft_overlay.s_axi_control.write(0x10,input_buffer.physical_address)\n",
    "fft_overlay.s_axi_control.write(0x1c,output_buffer.physical_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start running IP\n",
    "fft_overlay.s_axi_CTRL.write(0x00, 0x01)\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    reg = fft_overlay.s_axi_CTRL.read(0x00)\n",
    "    if reg != 1:\n",
    "        break\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"耗时：{}s\".format(end_time - start_time))\n",
    "xf = np.fft.rfftfreq(16384, 1/fs)\n",
    "\n",
    "#  Drawing and saving locally \n",
    "for frame_number in range(FRAME_COUNT):\n",
    "    s = find_top_notes(fft,TOP_NOTES)\n",
    "    fig = plot_fft(output_buffer[frame_number*(2**14):(frame_number+1)*(2**14)],xf,fs,s,RESOLUTION)\n",
    "    fig.write_image(f\"./content/frame{frame_number}.png\",scale=1)\n",
    "    py.iplot(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_buffer[10000:10009]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vo01yEzHeSu"
   },
   "source": [
    "Use [ffmpeg](https://ffmpeg.org/) to combine the input audio WAV and the individual frame images into a MP4 video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzPw9WT-Lfmy",
    "outputId": "902b4759-c184-44e5-c009-a7f8b15f6ea5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ffmpeg -y -r {FPS} -f image2 -s 1920x1080 -i /home/xilinx/jupyter_notebooks/fft_prjs/content/frame%d.png -i {AUDIO_FILE} -c:v libx264 -pix_fmt yuv420p movie.mp4"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
